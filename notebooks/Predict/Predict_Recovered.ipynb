{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the model in a inference behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load a cv config with all experiment parameters\n",
    "2. Load the corresponding data, \n",
    "3. create a train and validation generator with the given parameters, exclusive the augmentation parameters\n",
    "4. reconstruct the model with the given parameters, (we have custom loss functions, simple model.load() will not work)\n",
    "5. load and apply the corresponding weights (with respect to the distributed training strategy)\n",
    "6. predict the targt vectors with the train and val generators (make sure that we change the batchsize to 1, and avoid shuffle so that we get all files)\n",
    "7. write the gt and predictions as numpy into the corresponding experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/ssd/git/wft21_septum_landmark_detection\n",
      "['/gpu:0', '/gpu:1']\n"
     ]
    }
   ],
   "source": [
    "#checks_out\n",
    "\n",
    "# ------------------------------------------define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "# ------------------------------------------define GPU id/s to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "# ------------------------------------------jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# ------------------------------------------ import helpers\n",
    "# this should import glob, os, and some other standard libs to keep this cell clean\n",
    "# local imports\n",
    "from src.utils.Notebook_imports import *\n",
    "from src.utils.Utils_io import Console_and_file_logger, init_config\n",
    "\n",
    "# import external libs\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from ipyfilechooser import FileChooser\n",
    "#import nrrd as nrrd # https://pypi.org/project/pynrrd/\n",
    "from src.data.Generators import DataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a config into the global namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd2543d81ec4297a082dd058224e685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/mnt/ssd/git/wft21_septum_landmark_detection/exp/temp', filename='', title='HTML(value='', l…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5185ace912894db8938ac8aadce1566b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Run Interact', style=ButtonStyle()), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checks_out\n",
    "\n",
    "exp_config_chooser = FileChooser(os.path.join(os.getcwd(),'exp/temp'), '')\n",
    "display(exp_config_chooser)\n",
    "@interact_manual\n",
    "def load_config():\n",
    "\n",
    "    global exp_config_chooser, config\n",
    "    \"\"\"\n",
    "    load an experiment config\n",
    "    \"\"\"\n",
    "    if 'exp_config_chooser' in globals():\n",
    "        config_file  = exp_config_chooser.selected\n",
    "    else:\n",
    "        print('no config chooser found')\n",
    "\n",
    "    # load the experiment config\n",
    "    with open(config_file, encoding='utf-8') as data_file:\n",
    "        config = json.loads(data_file.read())\n",
    "    globals().update(config)\n",
    "    Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "    logging.info('Loaded config for experiment: {}'.format(config['EXPERIMENT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF_FOLDS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6d358a32da74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDF_FOLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shows dataframe with all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF_FOLDS' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DF_FOLDS)\n",
    "df.head() # shows dataframe with all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # useful for troubleshooting , showcases entire dataframe\n",
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None) \n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ea18c8ca964d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# load dataframe with all patients and corresponding fold (in our case only fold0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shows dataframe with all files for fold 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df[df['fold']==3] # load dataframe with all patients and corresponding fold (in our case only fold0)\n",
    "df.head() # shows dataframe with all files for fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = df[df['modality']==train]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Frage: ob Reihenfolge von p gleich ist wie die in den predictions / groundtruths.\n",
    "Easy fix evtl: beide sorten\n",
    "for p in sorted(df['patient'].unique()):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient001\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient002\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient003\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient004\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient005\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient006\n",
      "22\n",
      "length of ed_f 11\n",
      "length of es_f 11\n",
      "patient007\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient008\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient009\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient010\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient011\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient012\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient013\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient014\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient015\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient016\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient017\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient018\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient019\n",
      "22\n",
      "length of ed_f 11\n",
      "length of es_f 11\n",
      "patient020\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient021\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient022\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient023\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient024\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient025\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient026\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient027\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient028\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient029\n",
      "22\n",
      "length of ed_f 11\n",
      "length of es_f 11\n",
      "patient030\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient031\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient032\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient033\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient034\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient035\n",
      "26\n",
      "length of ed_f 13\n",
      "length of es_f 13\n",
      "patient036\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient037\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient038\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient039\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient040\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient041\n",
      "12\n",
      "length of ed_f 6\n",
      "length of es_f 6\n",
      "patient042\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient043\n",
      "24\n",
      "length of ed_f 12\n",
      "length of es_f 12\n",
      "patient044\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient045\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient046\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient047\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient048\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient049\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient050\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient051\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient052\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient053\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient054\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient055\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient056\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient057\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient058\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient059\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient060\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient061\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient062\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient063\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient064\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient065\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient066\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient067\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient068\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient069\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient070\n",
      "12\n",
      "length of ed_f 6\n",
      "length of es_f 6\n",
      "patient071\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient072\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient073\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient074\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient075\n",
      "28\n",
      "length of ed_f 14\n",
      "length of es_f 14\n",
      "patient076\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient077\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient078\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient079\n",
      "18\n",
      "length of ed_f 9\n",
      "length of es_f 9\n",
      "patient080\n",
      "12\n",
      "length of ed_f 6\n",
      "length of es_f 6\n",
      "patient081\n",
      "34\n",
      "length of ed_f 17\n",
      "length of es_f 17\n",
      "patient082\n",
      "32\n",
      "length of ed_f 16\n",
      "length of es_f 16\n",
      "patient083\n",
      "12\n",
      "length of ed_f 6\n",
      "length of es_f 6\n",
      "patient084\n",
      "24\n",
      "length of ed_f 12\n",
      "length of es_f 12\n",
      "patient085\n",
      "30\n",
      "length of ed_f 15\n",
      "length of es_f 15\n",
      "patient086\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient087\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient088\n",
      "32\n",
      "length of ed_f 16\n",
      "length of es_f 16\n",
      "patient089\n",
      "12\n",
      "length of ed_f 6\n",
      "length of es_f 6\n",
      "patient090\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient091\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient092\n",
      "30\n",
      "length of ed_f 15\n",
      "length of es_f 15\n",
      "patient093\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient094\n",
      "20\n",
      "length of ed_f 10\n",
      "length of es_f 10\n",
      "patient095\n",
      "28\n",
      "length of ed_f 14\n",
      "length of es_f 14\n",
      "patient096\n",
      "36\n",
      "length of ed_f 18\n",
      "length of es_f 18\n",
      "patient097\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n",
      "patient098\n",
      "14\n",
      "length of ed_f 7\n",
      "length of es_f 7\n",
      "patient099\n",
      "32\n",
      "length of ed_f 16\n",
      "length of es_f 16\n",
      "patient100\n",
      "16\n",
      "length of ed_f 8\n",
      "length of es_f 8\n"
     ]
    }
   ],
   "source": [
    "#for p in df['patient'].unique(): # show only data on 'unique' patients to sum up folds and slices\n",
    "for p in sorted(df['patient'].unique()):\n",
    "    print(p)\n",
    "    files_ = df[df['patient'] ==p]['x_path'].values\n",
    "    print(len(files_)) # shows amount of slices for each patient\n",
    "    #print(files_[0]) # files is a list with the name of all patient data\n",
    "    ed_f = files_[:len(files_)//2]\n",
    "    es_f = files_[len(files_)//2:]\n",
    "    print('length of ed_f ' + str(len(ed_f)))\n",
    "    print('length of es_f ' + str(len(es_f)))\n",
    "    #print('this is ed_f ' + ed_f)\n",
    "    #print('this is es_f ' + es_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Each patient has two 3D-Volumes, corresponding to the end diastolic (ed) and end systolic (es) phase of the cardiac cycle. \n",
    "The amount of slices remain the same across volumes of the same patient, allowing us to sort the files and half them to reconstruct the corresponding two 3d-volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ed_f = files_[:len(files_)//2]\n",
    "# es_f = files_[len(files_)//2:]\n",
    "# print(len(ed_f))\n",
    "# print(len(es_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the corresponding file names for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:35:47,083 INFO Found 1902 images/masks in /mnt/ssd/data/WFT_MRT21/Export_2021-05-26_16_03\n",
      "2021-07-06 16:35:47,084 INFO Patients train: 75\n",
      "2021-07-06 16:35:47,139 INFO Selected 1406 of 1902 files with 75 of 100 patients for training fold 3\n",
      "2021-07-06 16:35:47,140 INFO SAX train CMR: 1406, SAX train masks: 1406\n",
      "2021-07-06 16:35:47,140 INFO SAX val CMR: 496, SAX val masks: 496\n"
     ]
    }
   ],
   "source": [
    "#checks_out\n",
    "# Load SAX volumes\n",
    "from src.data.Dataset import get_trainings_files\n",
    "x_train_sax, y_train_sax, x_val_sax, y_val_sax = get_trainings_files(data_path=DATA_PATH_SAX,\n",
    "                                                                     path_to_folds_df=DF_FOLDS,\n",
    "                                                                     fold=FOLD)\n",
    "logging.info('SAX train CMR: {}, SAX train masks: {}'.format(len(x_train_sax), len(y_train_sax)))\n",
    "logging.info('SAX val CMR: {}, SAX val masks: {}'.format(len(x_val_sax), len(y_val_sax)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the same the train and val generators as used for the training of this model\n",
    "\n",
    "Make sure that:\n",
    "- no shuffle\n",
    "- no augmentation (classic and temporal)\n",
    "- batchsize equal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:35:47,933 INFO Create DataGenerator\n",
      "2021-07-06 16:35:47,939 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 1406 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:35:47,939 INFO No augmentation\n",
      "2021-07-06 16:35:47,940 INFO Create DataGenerator\n",
      "2021-07-06 16:35:47,942 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 496 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:35:47,943 INFO No augmentation\n"
     ]
    }
   ],
   "source": [
    "#checks_out\n",
    "# DataGenerator for SAX, changed from PhaseRegression Generator\n",
    "# logging.getLogger().setLevel(logging.INFO)\n",
    "from src.data.Generators import DataGenerator\n",
    "config['SHUFFLE'] = False\n",
    "config['AUGMENT'] = False\n",
    "config['AUGMENT_GRID'] = False# make sure no augmentation will be applied to the validation data\n",
    "config['HIST_MATCHING'] = False\n",
    "config['BATCHSIZE'] = 1\n",
    "batch_generator = DataGenerator(x_train_sax, y_train_sax, config=config)\n",
    "# create another config for the validation data, \n",
    "# by this we can have a different set of parameters for both generators\n",
    "val_config = config.copy()\n",
    "validation_generator = DataGenerator(x_val_sax, y_val_sax, config=val_config) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_val_sax contains 25 patients currently , evently distributed across all patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_val_sax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model, load and set the corresponding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:35:49,909 INFO Create model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using tensorflow, need to monkey patch\n",
      "tf.python.backend.slice overwritten by monkey patch\n",
      "(None, 128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:35:51,507 INFO loaded model weights as h5 file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 128, 32) 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 128, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 32) 9248        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   36928       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 128)  147584      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 256)  590080      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 512)    1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 8, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 512)    2359808     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 16, 16, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  1179904     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 512)  0           conv2d_10[0][0]                  \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 256)  590080      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 128)  295040      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 256)  0           conv2d_13[0][0]                  \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 128)  147584      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 64)   73792       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 128)  0           conv2d_16[0][0]                  \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 64)   36928       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 32) 18464       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 64) 0           conv2d_19[0][0]                  \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 32) 128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128, 128, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 32) 9248        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 32) 128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "unet (Conv2D)                   (None, 128, 128, 2)  66          batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 8,641,730\n",
      "Trainable params: 8,635,842\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#checks_out\n",
    "# Create Neural Network for SAX as U-Net\n",
    "import src.models.Unets as modelmanager\n",
    "# create a model\n",
    "logging.info('Create model')\n",
    "model = modelmanager.create_unet(config)\n",
    "model.load_weights(os.path.join(config['MODEL_PATH'],'model.h5'))\n",
    "logging.info('loaded model weights as h5 file')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on the validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94d884e00fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# predict on the validation generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# predict on the validation generator\n",
    "preds = model.predict(validation_generator)\n",
    "logging.info(preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Predict on the training split\n",
    "\n",
    "### predicting on both needs two seperate runs of the notebook and adjustment of some code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict on the training generator\n",
    "# preds = model.predict(batch_generator)\n",
    "# logging.info(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create one numpy object from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:21:23,284 INFO (476, 128, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "# get all ground truth vectors\n",
    "gts = np.stack([np.squeeze(y) for x, y in validation_generator])\n",
    "logging.info(gts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:21:24,766 INFO (476, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# get all original cmr images\n",
    "gts_cmr = np.stack([np.squeeze(x) for x, y in validation_generator])\n",
    "logging.info(gts_cmr.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q: Unsure what the different np.squeeze functions do. Docs say it removes axes of lenght = 1. But why do we call in once on x and once on y? What exactly are we calling it on? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save gt and pred into experiment folder\n",
    "saves groundtruth based on np.stack with gts and predictions as one numpy stack under the pred_filename as a .npy file. The numpy stack is later used to create the images based on the arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:21:26,122 INFO saved as: \n",
      "exp/temp/TeaMRT_Exp1/2021-07-06_13_48/predictions_2021-07-06_16_21/gtpred_fold0.npy \n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#checks_out\n",
    "pred_path = os.path.join(config['EXP_PATH'], 'predictions_'+ str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "ensure_dir(pred_path)\n",
    "pred_filename = os.path.join(pred_path, 'gtpred_fold{}.npy'.format(config['FOLD'])) #names file according to fold, in our case only fold0\n",
    "np.save(pred_filename, np.stack([gts, preds], axis=0)) \n",
    "logging.info('saved as: \\n{} \\ndone!'.format(pred_filename))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "the predictions are loaded as an array stack. array stack 0 corresponds to the groundtruths , array stack 1 to the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of the numpy.stack is(2, 476, 128, 128, 2)\n",
      "loading from: /mnt/ssd/git/wft21_septum_landmark_detection/exp/temp/TeaMRT_Exp1/2021-07-06_13_48/predictions_2021-07-06_16_21/gtpred_fold0.npy\n"
     ]
    }
   ],
   "source": [
    "#checks_out\n",
    "\n",
    "#np.load('/mnt/ssd/git/wft21_septum_landmark_detection/{}'.format(pred_filename))\n",
    "\n",
    "stack = np.load('/mnt/ssd/git/wft21_septum_landmark_detection/{}'.format(pred_filename)) # loads current predictions from folder\n",
    "print('the shape of the numpy.stack is' + str(np.shape(stack)))\n",
    "print(('loading from: /mnt/ssd/git/wft21_septum_landmark_detection/{}'.format(pred_filename)))\n",
    "\n",
    "#for-loop over stack --> reading numpy and transferring with pynrrd. pad_and_crop function applied. saving with the name of original file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "this is where the loops need to come in I think. It reads through all the data, and creates a numpy stack from it. Sorting of data can be seen here aswell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Images from Arrays\n",
    "\n",
    "One-hot encoding of annotations. Channel 1 is transformed to pixels with the value of 1, Channel 2 is transformed to pixels with the value of 2. This is the same format to annotations created as .nrrd-files with the MITK-Toolkit. \n",
    "\n",
    "Both the predictions and groundtruths are recreated using this method. This is the simplest way for us to scale the predictions to the same size of the groundtruth images, without needing implement undoing of the generator steps and dealing with differenzt sizing or spacing issues. \n",
    "\n",
    "Using the sitk toolkit a total of three images are created per training file. One representing the file without any annotations, one with our groundtruth and one with the prediction of the model.\n",
    "\n",
    "The above created numpy stack is used for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "#checks_out\n",
    "\n",
    "gts = stack[0]\n",
    "preds = stack[1]\n",
    "\n",
    "\n",
    "# upper = 1, lower == 2\n",
    "# transform to int representation (one-hot)\n",
    "gts_flat = np.zeros((gts.shape[:-1]))\n",
    "gts_flat[gts[...,0]>0.5] = 1\n",
    "gts_flat[gts[...,1]>0.5] = 2\n",
    "\n",
    "preds_flat = np.zeros((gts.shape[:-1]))\n",
    "preds_flat[preds[...,0]>0.5] = 1\n",
    "preds_flat[preds[...,1]>0.5] = 2\n",
    "print(preds_flat.shape)\n",
    "#print(preds_flat) #NotIncluded\n",
    "gt_sitks = [sitk.GetImageFromArray(elem) for elem in gts_flat]\n",
    "pred_sitks = [sitk.GetImageFromArray(elem) for elem in preds_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 11:24:43,928 INFO saved as: \n",
      "exp/temp/spacing_1_8/2021-05-26_13_40/predictions_flat2021-07-06_11_24/gtpred_fold0.npy \n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# save preds_flat to understand what they look like\n",
    "\n",
    "pred_flat_path = os.path.join(config['EXP_PATH'], 'predictions_flat'+ str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "ensure_dir(pred_flat_path)\n",
    "pred_flat_filename = os.path.join(pred_flat_path, 'gtpred_fold{}.npy'.format(config['FOLD'])) #names file according to fold, in our case only fold0\n",
    "\n",
    "\n",
    "np.save(pred_flat_filename, np.stack(preds_flat[:10], axis=0)) # saves a numpy stack of first 10 files only???\n",
    "\n",
    "logging.info('saved as: \\n{} \\ndone!'.format(pred_flat_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sitk.WriteImage functions all use numpy stacks. This is to join corresponding images of the same 3d-volume to one image. \n",
    "\n",
    "Theoretically I just care about the numbers of the preds... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# write 3d_nrrd file of groundtruth to disk\n",
    "\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_flat[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_gt.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 3d_nrrd file of predictions to disk\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.stack(preds_flat[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_pred.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 3d_nrrd file of original image to disk\n",
    "\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_cmr[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_cmr.nrrd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Combiner"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Current structure: \n",
    "ed = 0 - first half\n",
    "es = second half - end\n",
    "aber : keine Nennung von wo genau, nur die files. Keine Nummerierung. \n",
    "Aber wir wissen die jeweilige Länge der files\n",
    "\n",
    "if I had a counter: \n",
    "\n",
    "bsp: wir sind bei 70 , neues frame mit 20 , pro 3d vol 10\n",
    "current counter : 80\n",
    "\n",
    "last count + 1 + lenght // 2 = ed_f \n",
    "(71-80)\n",
    "last count + 1 -  length // 2 = es_f\n",
    "(81-90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # write 3d_nrrd file to disk\n",
    "# #for p in df['patient'].unique(): # show only data on 'unique' patients to sum up folds and slices\n",
    "# filecounter = 0\n",
    "# for p in sorted(df['patient'].unique()):\n",
    "#     print(p)\n",
    "#     files_ = df[df['patient'] ==p]['x_path'].values\n",
    "#     print(len(files_)) # shows amount of slices for each patient\n",
    "#     #print(files_[0]) # files is a list with the name of all patient data\n",
    "#     ed_f = files_[:len(files_)//2]\n",
    "#     es_f = files_[len(files_)//2:]\n",
    "#     print('length of ed_f ' + str(len(ed_f)))\n",
    "#     print('length of es_f ' + str(len(es_f)))\n",
    "#     #print('this is ed_f ' + ed_f)\n",
    "#     #print('this is es_f ' + es_f)\n",
    "#     print('filecounter starts at at: ' + str(filecounter))\n",
    "#     limit = filecounter + (len(files_)//2)\n",
    "#     print('limit starts at: ' + str(limit))\n",
    "    \n",
    "    \n",
    "#     print('WRITING from :' + str(filecounter) + ' to ' + str(limit))\n",
    "#     #sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_flat[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_gt.nrrd')\n",
    "#     #sitk.WriteImage(sitk.GetImageFromArray(np.stack(preds_flat[filecounter:len(files_)//2], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/ preds{}_ed.nrrd'.format(str(p))\n",
    "#     sitk.WriteImage(sitk.GetImageFromArray(np.stack(preds_flat[filecounter:limit], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/preds_{}_ed.nrrd'.format(str(p)))\n",
    "#     #sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_cmr[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_cmr.nrrd')\n",
    "    \n",
    "#     #sitk.WriteImage(sitk.GetImageFromArray(np.stack(preds_flat[11:20], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/checkpred.nrrd')\n",
    "    \n",
    "    \n",
    "#     filecounter = filecounter + (len(files_)//2)\n",
    "#     limit = filecounter + (len(files_)//2)\n",
    "#     print('first round done. filecounter at: ' + str(filecounter) + ', limit at ' + str(limit))\n",
    "    \n",
    "    \n",
    "#     print('WRITING from :' + str(filecounter+1) + ' to ' + str(limit))\n",
    "#     sitk.WriteImage(sitk.GetImageFromArray(np.stack(preds_flat[filecounter:limit], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/preds_{}_es.nrrd'.format(str(p)))\n",
    "#     #sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_flat[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_gt.nrrd')\n",
    "#     #sitk.WriteImage(sitk.GetImageFromArray(np.stack(preds_flat[filecounter:len(files_)//2], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/preds{}_ed.nrrd'.format(p))\n",
    "#     #sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_cmr[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_cmr.nrrd')\n",
    "    \n",
    "#     filecounter = filecounter + (len(files_)//2)\n",
    "#     limit = 0\n",
    "#     print('patient done. filecounter exits at: ' + str(filecounter) + ', limit will be reinitialized in next pass.')\n",
    "    \n",
    "#     print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fast hack which aligns the patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of patients for fast testing\n",
    "patients = [p for p in sorted(df['patient'].unique())]\n",
    "#patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-06 16:36:24,317 INFO patient007\n",
      "2021-07-06 16:36:24,318 INFO 20\n",
      "2021-07-06 16:36:24,318 INFO length of ed_f 10\n",
      "2021-07-06 16:36:24,318 INFO length of es_f 10\n",
      "2021-07-06 16:36:24,319 INFO patient: patient007, phase: ED, files: 10\n",
      "2021-07-06 16:36:24,319 INFO Create DataGenerator\n",
      "2021-07-06 16:36:24,320 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:24,320 INFO No augmentation\n",
      "2021-07-06 16:36:24,372 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:24,407 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:26,070 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:26,072 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,072 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,072 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,075 INFO patient: patient007, phase: ES, files: 10\n",
      "2021-07-06 16:36:26,075 INFO Create DataGenerator\n",
      "2021-07-06 16:36:26,076 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:26,076 INFO No augmentation\n",
      "2021-07-06 16:36:26,112 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:26,146 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:26,301 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:26,303 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,303 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,303 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,305 INFO patient008\n",
      "2021-07-06 16:36:26,306 INFO 20\n",
      "2021-07-06 16:36:26,306 INFO length of ed_f 10\n",
      "2021-07-06 16:36:26,306 INFO length of es_f 10\n",
      "2021-07-06 16:36:26,307 INFO patient: patient008, phase: ED, files: 10\n",
      "2021-07-06 16:36:26,307 INFO Create DataGenerator\n",
      "2021-07-06 16:36:26,307 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:26,307 INFO No augmentation\n",
      "2021-07-06 16:36:26,340 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:26,374 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:26,524 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:26,525 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,525 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,526 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,528 INFO patient: patient008, phase: ES, files: 10\n",
      "2021-07-06 16:36:26,528 INFO Create DataGenerator\n",
      "2021-07-06 16:36:26,528 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:26,528 INFO No augmentation\n",
      "2021-07-06 16:36:26,562 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:26,595 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:26,741 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:26,742 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,743 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,743 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:26,745 INFO patient011\n",
      "2021-07-06 16:36:26,745 INFO 18\n",
      "2021-07-06 16:36:26,746 INFO length of ed_f 9\n",
      "2021-07-06 16:36:26,746 INFO length of es_f 9\n",
      "2021-07-06 16:36:26,746 INFO patient: patient011, phase: ED, files: 9\n",
      "2021-07-06 16:36:26,746 INFO Create DataGenerator\n",
      "2021-07-06 16:36:26,747 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 9 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:26,747 INFO No augmentation\n",
      "2021-07-06 16:36:26,776 INFO groundtruth shape(9, 128, 128, 2)\n",
      "2021-07-06 16:36:26,807 INFO original cmr shape(9, 128, 128)\n",
      "2021-07-06 16:36:26,960 INFO (9, 128, 128, 2)\n",
      "2021-07-06 16:36:26,961 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:26,961 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:26,961 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:26,963 INFO patient: patient011, phase: ES, files: 9\n",
      "2021-07-06 16:36:26,964 INFO Create DataGenerator\n",
      "2021-07-06 16:36:26,964 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 9 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:26,964 INFO No augmentation\n",
      "2021-07-06 16:36:26,994 INFO groundtruth shape(9, 128, 128, 2)\n",
      "2021-07-06 16:36:27,025 INFO original cmr shape(9, 128, 128)\n",
      "2021-07-06 16:36:27,194 INFO (9, 128, 128, 2)\n",
      "2021-07-06 16:36:27,195 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:27,195 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:27,195 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:27,197 INFO patient013\n",
      "2021-07-06 16:36:27,198 INFO 20\n",
      "2021-07-06 16:36:27,198 INFO length of ed_f 10\n",
      "2021-07-06 16:36:27,198 INFO length of es_f 10\n",
      "2021-07-06 16:36:27,198 INFO patient: patient013, phase: ED, files: 10\n",
      "2021-07-06 16:36:27,199 INFO Create DataGenerator\n",
      "2021-07-06 16:36:27,199 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:27,200 INFO No augmentation\n",
      "2021-07-06 16:36:27,233 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:27,267 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:27,422 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:27,423 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:27,423 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:27,423 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:27,425 INFO patient: patient013, phase: ES, files: 10\n",
      "2021-07-06 16:36:27,425 INFO Create DataGenerator\n",
      "2021-07-06 16:36:27,426 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:27,426 INFO No augmentation\n",
      "2021-07-06 16:36:27,458 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:27,491 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:27,638 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:27,640 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:27,640 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:27,641 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:27,643 INFO patient015\n",
      "2021-07-06 16:36:27,644 INFO 18\n",
      "2021-07-06 16:36:27,644 INFO length of ed_f 9\n",
      "2021-07-06 16:36:27,644 INFO length of es_f 9\n",
      "2021-07-06 16:36:27,644 INFO patient: patient015, phase: ED, files: 9\n",
      "2021-07-06 16:36:27,645 INFO Create DataGenerator\n",
      "2021-07-06 16:36:27,646 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 9 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:27,646 INFO No augmentation\n",
      "2021-07-06 16:36:27,675 INFO groundtruth shape(9, 128, 128, 2)\n",
      "2021-07-06 16:36:27,705 INFO original cmr shape(9, 128, 128)\n",
      "2021-07-06 16:36:27,860 INFO (9, 128, 128, 2)\n",
      "2021-07-06 16:36:27,862 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:27,862 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:27,862 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:27,864 INFO patient: patient015, phase: ES, files: 9\n",
      "2021-07-06 16:36:27,864 INFO Create DataGenerator\n",
      "2021-07-06 16:36:27,865 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 9 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:27,865 INFO No augmentation\n",
      "2021-07-06 16:36:27,894 INFO groundtruth shape(9, 128, 128, 2)\n",
      "2021-07-06 16:36:27,924 INFO original cmr shape(9, 128, 128)\n",
      "2021-07-06 16:36:28,076 INFO (9, 128, 128, 2)\n",
      "2021-07-06 16:36:28,077 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:28,078 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:28,078 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:28,080 INFO patient027\n",
      "2021-07-06 16:36:28,080 INFO 20\n",
      "2021-07-06 16:36:28,081 INFO length of ed_f 10\n",
      "2021-07-06 16:36:28,081 INFO length of es_f 10\n",
      "2021-07-06 16:36:28,081 INFO patient: patient027, phase: ED, files: 10\n",
      "2021-07-06 16:36:28,082 INFO Create DataGenerator\n",
      "2021-07-06 16:36:28,082 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:28,082 INFO No augmentation\n",
      "2021-07-06 16:36:28,115 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:28,150 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:28,302 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:28,303 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,303 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,304 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,305 INFO patient: patient027, phase: ES, files: 10\n",
      "2021-07-06 16:36:28,306 INFO Create DataGenerator\n",
      "2021-07-06 16:36:28,306 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:28,306 INFO No augmentation\n",
      "2021-07-06 16:36:28,340 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:28,372 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:28,528 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:28,529 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,530 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,530 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,532 INFO patient028\n",
      "2021-07-06 16:36:28,532 INFO 20\n",
      "2021-07-06 16:36:28,533 INFO length of ed_f 10\n",
      "2021-07-06 16:36:28,533 INFO length of es_f 10\n",
      "2021-07-06 16:36:28,533 INFO patient: patient028, phase: ED, files: 10\n",
      "2021-07-06 16:36:28,533 INFO Create DataGenerator\n",
      "2021-07-06 16:36:28,534 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:28,534 INFO No augmentation\n",
      "2021-07-06 16:36:28,568 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:28,602 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:28,757 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:28,759 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,759 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,759 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:28,761 INFO patient: patient028, phase: ES, files: 10\n",
      "2021-07-06 16:36:28,762 INFO Create DataGenerator\n",
      "2021-07-06 16:36:28,762 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:28,763 INFO No augmentation\n",
      "2021-07-06 16:36:28,801 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:28,837 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:28,998 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:28,999 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,000 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,000 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,002 INFO patient031\n",
      "2021-07-06 16:36:29,003 INFO 20\n",
      "2021-07-06 16:36:29,003 INFO length of ed_f 10\n",
      "2021-07-06 16:36:29,004 INFO length of es_f 10\n",
      "2021-07-06 16:36:29,004 INFO patient: patient031, phase: ED, files: 10\n",
      "2021-07-06 16:36:29,004 INFO Create DataGenerator\n",
      "2021-07-06 16:36:29,005 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:29,005 INFO No augmentation\n",
      "2021-07-06 16:36:29,039 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:29,073 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:29,241 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:29,242 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,243 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,243 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,245 INFO patient: patient031, phase: ES, files: 10\n",
      "2021-07-06 16:36:29,245 INFO Create DataGenerator\n",
      "2021-07-06 16:36:29,246 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:29,246 INFO No augmentation\n",
      "2021-07-06 16:36:29,279 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:29,311 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:29,463 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:29,465 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,465 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,465 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,468 INFO patient033\n",
      "2021-07-06 16:36:29,468 INFO 20\n",
      "2021-07-06 16:36:29,468 INFO length of ed_f 10\n",
      "2021-07-06 16:36:29,468 INFO length of es_f 10\n",
      "2021-07-06 16:36:29,469 INFO patient: patient033, phase: ED, files: 10\n",
      "2021-07-06 16:36:29,469 INFO Create DataGenerator\n",
      "2021-07-06 16:36:29,469 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:29,470 INFO No augmentation\n",
      "2021-07-06 16:36:29,503 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:29,538 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:29,691 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:29,692 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,692 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,693 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,695 INFO patient: patient033, phase: ES, files: 10\n",
      "2021-07-06 16:36:29,695 INFO Create DataGenerator\n",
      "2021-07-06 16:36:29,695 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:29,696 INFO No augmentation\n",
      "2021-07-06 16:36:29,728 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:29,761 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:29,908 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:29,909 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,910 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,910 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:29,913 INFO patient035\n",
      "2021-07-06 16:36:29,913 INFO 26\n",
      "2021-07-06 16:36:29,914 INFO length of ed_f 13\n",
      "2021-07-06 16:36:29,914 INFO length of es_f 13\n",
      "2021-07-06 16:36:29,914 INFO patient: patient035, phase: ED, files: 13\n",
      "2021-07-06 16:36:29,914 INFO Create DataGenerator\n",
      "2021-07-06 16:36:29,915 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 13 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:29,915 INFO No augmentation\n",
      "2021-07-06 16:36:29,959 INFO groundtruth shape(13, 128, 128, 2)\n",
      "2021-07-06 16:36:30,002 INFO original cmr shape(13, 128, 128)\n",
      "2021-07-06 16:36:30,161 INFO (13, 128, 128, 2)\n",
      "2021-07-06 16:36:30,162 INFO (13, 128, 128)\n",
      "2021-07-06 16:36:30,163 INFO (13, 128, 128)\n",
      "2021-07-06 16:36:30,163 INFO (13, 128, 128)\n",
      "2021-07-06 16:36:30,165 INFO patient: patient035, phase: ES, files: 13\n",
      "2021-07-06 16:36:30,166 INFO Create DataGenerator\n",
      "2021-07-06 16:36:30,166 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 13 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:30,167 INFO No augmentation\n",
      "2021-07-06 16:36:30,212 INFO groundtruth shape(13, 128, 128, 2)\n",
      "2021-07-06 16:36:30,255 INFO original cmr shape(13, 128, 128)\n",
      "2021-07-06 16:36:30,427 INFO (13, 128, 128, 2)\n",
      "2021-07-06 16:36:30,428 INFO (13, 128, 128)\n",
      "2021-07-06 16:36:30,428 INFO (13, 128, 128)\n",
      "2021-07-06 16:36:30,429 INFO (13, 128, 128)\n",
      "2021-07-06 16:36:30,431 INFO patient047\n",
      "2021-07-06 16:36:30,431 INFO 18\n",
      "2021-07-06 16:36:30,431 INFO length of ed_f 9\n",
      "2021-07-06 16:36:30,432 INFO length of es_f 9\n",
      "2021-07-06 16:36:30,432 INFO patient: patient047, phase: ED, files: 9\n",
      "2021-07-06 16:36:30,432 INFO Create DataGenerator\n",
      "2021-07-06 16:36:30,433 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 9 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:30,433 INFO No augmentation\n",
      "2021-07-06 16:36:30,463 INFO groundtruth shape(9, 128, 128, 2)\n",
      "2021-07-06 16:36:30,493 INFO original cmr shape(9, 128, 128)\n",
      "2021-07-06 16:36:30,633 INFO (9, 128, 128, 2)\n",
      "2021-07-06 16:36:30,634 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:30,635 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:30,635 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:30,637 INFO patient: patient047, phase: ES, files: 9\n",
      "2021-07-06 16:36:30,637 INFO Create DataGenerator\n",
      "2021-07-06 16:36:30,637 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 9 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:30,638 INFO No augmentation\n",
      "2021-07-06 16:36:30,668 INFO groundtruth shape(9, 128, 128, 2)\n",
      "2021-07-06 16:36:30,697 INFO original cmr shape(9, 128, 128)\n",
      "2021-07-06 16:36:30,841 INFO (9, 128, 128, 2)\n",
      "2021-07-06 16:36:30,842 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:30,843 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:30,843 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:30,845 INFO patient048\n",
      "2021-07-06 16:36:30,846 INFO 16\n",
      "2021-07-06 16:36:30,846 INFO length of ed_f 8\n",
      "2021-07-06 16:36:30,846 INFO length of es_f 8\n",
      "2021-07-06 16:36:30,847 INFO patient: patient048, phase: ED, files: 8\n",
      "2021-07-06 16:36:30,847 INFO Create DataGenerator\n",
      "2021-07-06 16:36:30,848 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 8 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:30,848 INFO No augmentation\n",
      "2021-07-06 16:36:30,874 INFO groundtruth shape(8, 128, 128, 2)\n",
      "2021-07-06 16:36:30,901 INFO original cmr shape(8, 128, 128)\n",
      "2021-07-06 16:36:31,048 INFO (8, 128, 128, 2)\n",
      "2021-07-06 16:36:31,049 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:31,049 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:31,049 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:31,051 INFO patient: patient048, phase: ES, files: 8\n",
      "2021-07-06 16:36:31,051 INFO Create DataGenerator\n",
      "2021-07-06 16:36:31,052 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 8 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:31,052 INFO No augmentation\n",
      "2021-07-06 16:36:31,080 INFO groundtruth shape(8, 128, 128, 2)\n",
      "2021-07-06 16:36:31,107 INFO original cmr shape(8, 128, 128)\n",
      "2021-07-06 16:36:31,246 INFO (8, 128, 128, 2)\n",
      "2021-07-06 16:36:31,247 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:31,247 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:31,247 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:31,249 INFO patient051\n",
      "2021-07-06 16:36:31,249 INFO 20\n",
      "2021-07-06 16:36:31,250 INFO length of ed_f 10\n",
      "2021-07-06 16:36:31,250 INFO length of es_f 10\n",
      "2021-07-06 16:36:31,251 INFO patient: patient051, phase: ED, files: 10\n",
      "2021-07-06 16:36:31,251 INFO Create DataGenerator\n",
      "2021-07-06 16:36:31,251 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:31,252 INFO No augmentation\n",
      "2021-07-06 16:36:31,285 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:31,318 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:31,471 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:31,472 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:31,473 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:31,473 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:31,475 INFO patient: patient051, phase: ES, files: 10\n",
      "2021-07-06 16:36:31,476 INFO Create DataGenerator\n",
      "2021-07-06 16:36:31,476 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:31,477 INFO No augmentation\n",
      "2021-07-06 16:36:31,510 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:31,543 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:31,694 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:31,695 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:31,696 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:31,696 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:31,699 INFO patient053\n",
      "2021-07-06 16:36:31,699 INFO 14\n",
      "2021-07-06 16:36:31,699 INFO length of ed_f 7\n",
      "2021-07-06 16:36:31,700 INFO length of es_f 7\n",
      "2021-07-06 16:36:31,700 INFO patient: patient053, phase: ED, files: 7\n",
      "2021-07-06 16:36:31,700 INFO Create DataGenerator\n",
      "2021-07-06 16:36:31,701 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 7 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:31,701 INFO No augmentation\n",
      "2021-07-06 16:36:31,725 INFO groundtruth shape(7, 128, 128, 2)\n",
      "2021-07-06 16:36:31,748 INFO original cmr shape(7, 128, 128)\n",
      "2021-07-06 16:36:31,883 INFO (7, 128, 128, 2)\n",
      "2021-07-06 16:36:31,885 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:31,885 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:31,885 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:31,887 INFO patient: patient053, phase: ES, files: 7\n",
      "2021-07-06 16:36:31,888 INFO Create DataGenerator\n",
      "2021-07-06 16:36:31,888 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 7 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:31,888 INFO No augmentation\n",
      "2021-07-06 16:36:31,912 INFO groundtruth shape(7, 128, 128, 2)\n",
      "2021-07-06 16:36:31,934 INFO original cmr shape(7, 128, 128)\n",
      "2021-07-06 16:36:32,069 INFO (7, 128, 128, 2)\n",
      "2021-07-06 16:36:32,070 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:32,070 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:32,070 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:32,072 INFO patient055\n",
      "2021-07-06 16:36:32,073 INFO 18\n",
      "2021-07-06 16:36:32,073 INFO length of ed_f 9\n",
      "2021-07-06 16:36:32,073 INFO length of es_f 9\n",
      "2021-07-06 16:36:32,074 INFO patient: patient055, phase: ED, files: 9\n",
      "2021-07-06 16:36:32,074 INFO Create DataGenerator\n",
      "2021-07-06 16:36:32,075 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 9 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:32,075 INFO No augmentation\n",
      "2021-07-06 16:36:32,106 INFO groundtruth shape(9, 128, 128, 2)\n",
      "2021-07-06 16:36:32,136 INFO original cmr shape(9, 128, 128)\n",
      "2021-07-06 16:36:32,285 INFO (9, 128, 128, 2)\n",
      "2021-07-06 16:36:32,286 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:32,286 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:32,287 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:32,289 INFO patient: patient055, phase: ES, files: 9\n",
      "2021-07-06 16:36:32,289 INFO Create DataGenerator\n",
      "2021-07-06 16:36:32,290 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 9 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:32,290 INFO No augmentation\n",
      "2021-07-06 16:36:32,320 INFO groundtruth shape(9, 128, 128, 2)\n",
      "2021-07-06 16:36:32,351 INFO original cmr shape(9, 128, 128)\n",
      "2021-07-06 16:36:32,497 INFO (9, 128, 128, 2)\n",
      "2021-07-06 16:36:32,498 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:32,498 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:32,499 INFO (9, 128, 128)\n",
      "2021-07-06 16:36:32,501 INFO patient067\n",
      "2021-07-06 16:36:32,501 INFO 20\n",
      "2021-07-06 16:36:32,501 INFO length of ed_f 10\n",
      "2021-07-06 16:36:32,501 INFO length of es_f 10\n",
      "2021-07-06 16:36:32,502 INFO patient: patient067, phase: ED, files: 10\n",
      "2021-07-06 16:36:32,502 INFO Create DataGenerator\n",
      "2021-07-06 16:36:32,502 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:32,502 INFO No augmentation\n",
      "2021-07-06 16:36:32,534 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:32,566 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:32,708 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:32,709 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:32,710 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:32,710 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:32,712 INFO patient: patient067, phase: ES, files: 10\n",
      "2021-07-06 16:36:32,712 INFO Create DataGenerator\n",
      "2021-07-06 16:36:32,712 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:32,713 INFO No augmentation\n",
      "2021-07-06 16:36:32,744 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:32,775 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:32,920 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:32,921 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:32,922 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:32,922 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:32,924 INFO patient068\n",
      "2021-07-06 16:36:32,925 INFO 14\n",
      "2021-07-06 16:36:32,925 INFO length of ed_f 7\n",
      "2021-07-06 16:36:32,925 INFO length of es_f 7\n",
      "2021-07-06 16:36:32,926 INFO patient: patient068, phase: ED, files: 7\n",
      "2021-07-06 16:36:32,926 INFO Create DataGenerator\n",
      "2021-07-06 16:36:32,927 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 7 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:32,927 INFO No augmentation\n",
      "2021-07-06 16:36:32,950 INFO groundtruth shape(7, 128, 128, 2)\n",
      "2021-07-06 16:36:32,972 INFO original cmr shape(7, 128, 128)\n",
      "2021-07-06 16:36:33,104 INFO (7, 128, 128, 2)\n",
      "2021-07-06 16:36:33,105 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:33,106 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:33,106 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:33,108 INFO patient: patient068, phase: ES, files: 7\n",
      "2021-07-06 16:36:33,108 INFO Create DataGenerator\n",
      "2021-07-06 16:36:33,108 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 7 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:33,109 INFO No augmentation\n",
      "2021-07-06 16:36:33,133 INFO groundtruth shape(7, 128, 128, 2)\n",
      "2021-07-06 16:36:33,157 INFO original cmr shape(7, 128, 128)\n",
      "2021-07-06 16:36:33,297 INFO (7, 128, 128, 2)\n",
      "2021-07-06 16:36:33,298 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:33,299 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:33,299 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:33,301 INFO patient071\n",
      "2021-07-06 16:36:33,301 INFO 20\n",
      "2021-07-06 16:36:33,302 INFO length of ed_f 10\n",
      "2021-07-06 16:36:33,302 INFO length of es_f 10\n",
      "2021-07-06 16:36:33,302 INFO patient: patient071, phase: ED, files: 10\n",
      "2021-07-06 16:36:33,303 INFO Create DataGenerator\n",
      "2021-07-06 16:36:33,303 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:33,303 INFO No augmentation\n",
      "2021-07-06 16:36:33,336 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:33,368 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:33,513 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:33,514 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:33,514 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:33,515 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:33,517 INFO patient: patient071, phase: ES, files: 10\n",
      "2021-07-06 16:36:33,517 INFO Create DataGenerator\n",
      "2021-07-06 16:36:33,518 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:33,518 INFO No augmentation\n",
      "2021-07-06 16:36:33,550 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:33,581 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:33,823 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:33,825 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:33,825 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:33,825 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:33,827 INFO patient073\n",
      "2021-07-06 16:36:33,828 INFO 14\n",
      "2021-07-06 16:36:33,828 INFO length of ed_f 7\n",
      "2021-07-06 16:36:33,828 INFO length of es_f 7\n",
      "2021-07-06 16:36:33,828 INFO patient: patient073, phase: ED, files: 7\n",
      "2021-07-06 16:36:33,829 INFO Create DataGenerator\n",
      "2021-07-06 16:36:33,829 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 7 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:33,829 INFO No augmentation\n",
      "2021-07-06 16:36:33,853 INFO groundtruth shape(7, 128, 128, 2)\n",
      "2021-07-06 16:36:33,877 INFO original cmr shape(7, 128, 128)\n",
      "2021-07-06 16:36:34,016 INFO (7, 128, 128, 2)\n",
      "2021-07-06 16:36:34,017 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:34,017 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:34,018 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:34,019 INFO patient: patient073, phase: ES, files: 7\n",
      "2021-07-06 16:36:34,020 INFO Create DataGenerator\n",
      "2021-07-06 16:36:34,020 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 7 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:34,020 INFO No augmentation\n",
      "2021-07-06 16:36:34,043 INFO groundtruth shape(7, 128, 128, 2)\n",
      "2021-07-06 16:36:34,066 INFO original cmr shape(7, 128, 128)\n",
      "2021-07-06 16:36:34,201 INFO (7, 128, 128, 2)\n",
      "2021-07-06 16:36:34,202 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:34,202 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:34,202 INFO (7, 128, 128)\n",
      "2021-07-06 16:36:34,205 INFO patient075\n",
      "2021-07-06 16:36:34,205 INFO 28\n",
      "2021-07-06 16:36:34,205 INFO length of ed_f 14\n",
      "2021-07-06 16:36:34,206 INFO length of es_f 14\n",
      "2021-07-06 16:36:34,206 INFO patient: patient075, phase: ED, files: 14\n",
      "2021-07-06 16:36:34,207 INFO Create DataGenerator\n",
      "2021-07-06 16:36:34,207 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 14 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:34,208 INFO No augmentation\n",
      "2021-07-06 16:36:34,252 INFO groundtruth shape(14, 128, 128, 2)\n",
      "2021-07-06 16:36:34,297 INFO original cmr shape(14, 128, 128)\n",
      "2021-07-06 16:36:34,469 INFO (14, 128, 128, 2)\n",
      "2021-07-06 16:36:34,470 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:34,470 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:34,471 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:34,473 INFO patient: patient075, phase: ES, files: 14\n",
      "2021-07-06 16:36:34,474 INFO Create DataGenerator\n",
      "2021-07-06 16:36:34,474 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 14 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:34,474 INFO No augmentation\n",
      "2021-07-06 16:36:34,519 INFO groundtruth shape(14, 128, 128, 2)\n",
      "2021-07-06 16:36:34,564 INFO original cmr shape(14, 128, 128)\n",
      "2021-07-06 16:36:34,726 INFO (14, 128, 128, 2)\n",
      "2021-07-06 16:36:34,728 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:34,728 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:34,728 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:34,731 INFO patient087\n",
      "2021-07-06 16:36:34,731 INFO 16\n",
      "2021-07-06 16:36:34,732 INFO length of ed_f 8\n",
      "2021-07-06 16:36:34,732 INFO length of es_f 8\n",
      "2021-07-06 16:36:34,733 INFO patient: patient087, phase: ED, files: 8\n",
      "2021-07-06 16:36:34,733 INFO Create DataGenerator\n",
      "2021-07-06 16:36:34,733 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 8 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:34,734 INFO No augmentation\n",
      "2021-07-06 16:36:34,760 INFO groundtruth shape(8, 128, 128, 2)\n",
      "2021-07-06 16:36:34,785 INFO original cmr shape(8, 128, 128)\n",
      "2021-07-06 16:36:34,922 INFO (8, 128, 128, 2)\n",
      "2021-07-06 16:36:34,923 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:34,923 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:34,923 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:34,925 INFO patient: patient087, phase: ES, files: 8\n",
      "2021-07-06 16:36:34,926 INFO Create DataGenerator\n",
      "2021-07-06 16:36:34,926 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 8 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:34,926 INFO No augmentation\n",
      "2021-07-06 16:36:34,952 INFO groundtruth shape(8, 128, 128, 2)\n",
      "2021-07-06 16:36:34,977 INFO original cmr shape(8, 128, 128)\n",
      "2021-07-06 16:36:35,113 INFO (8, 128, 128, 2)\n",
      "2021-07-06 16:36:35,114 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:35,115 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:35,115 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:35,117 INFO patient088\n",
      "2021-07-06 16:36:35,117 INFO 32\n",
      "2021-07-06 16:36:35,117 INFO length of ed_f 16\n",
      "2021-07-06 16:36:35,118 INFO length of es_f 16\n",
      "2021-07-06 16:36:35,118 INFO patient: patient088, phase: ED, files: 16\n",
      "2021-07-06 16:36:35,118 INFO Create DataGenerator\n",
      "2021-07-06 16:36:35,118 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 16 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:35,119 INFO No augmentation\n",
      "2021-07-06 16:36:35,169 INFO groundtruth shape(16, 128, 128, 2)\n",
      "2021-07-06 16:36:35,218 INFO original cmr shape(16, 128, 128)\n",
      "2021-07-06 16:36:35,406 INFO (16, 128, 128, 2)\n",
      "2021-07-06 16:36:35,407 INFO (16, 128, 128)\n",
      "2021-07-06 16:36:35,408 INFO (16, 128, 128)\n",
      "2021-07-06 16:36:35,408 INFO (16, 128, 128)\n",
      "2021-07-06 16:36:35,411 INFO patient: patient088, phase: ES, files: 16\n",
      "2021-07-06 16:36:35,411 INFO Create DataGenerator\n",
      "2021-07-06 16:36:35,411 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 16 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:35,412 INFO No augmentation\n",
      "2021-07-06 16:36:35,462 INFO groundtruth shape(16, 128, 128, 2)\n",
      "2021-07-06 16:36:35,512 INFO original cmr shape(16, 128, 128)\n",
      "2021-07-06 16:36:35,682 INFO (16, 128, 128, 2)\n",
      "2021-07-06 16:36:35,684 INFO (16, 128, 128)\n",
      "2021-07-06 16:36:35,684 INFO (16, 128, 128)\n",
      "2021-07-06 16:36:35,684 INFO (16, 128, 128)\n",
      "2021-07-06 16:36:35,688 INFO patient091\n",
      "2021-07-06 16:36:35,688 INFO 16\n",
      "2021-07-06 16:36:35,688 INFO length of ed_f 8\n",
      "2021-07-06 16:36:35,689 INFO length of es_f 8\n",
      "2021-07-06 16:36:35,689 INFO patient: patient091, phase: ED, files: 8\n",
      "2021-07-06 16:36:35,690 INFO Create DataGenerator\n",
      "2021-07-06 16:36:35,690 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 8 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:35,691 INFO No augmentation\n",
      "2021-07-06 16:36:35,717 INFO groundtruth shape(8, 128, 128, 2)\n",
      "2021-07-06 16:36:35,743 INFO original cmr shape(8, 128, 128)\n",
      "2021-07-06 16:36:35,881 INFO (8, 128, 128, 2)\n",
      "2021-07-06 16:36:35,882 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:35,882 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:35,883 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:35,885 INFO patient: patient091, phase: ES, files: 8\n",
      "2021-07-06 16:36:35,885 INFO Create DataGenerator\n",
      "2021-07-06 16:36:35,885 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 8 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:35,886 INFO No augmentation\n",
      "2021-07-06 16:36:35,911 INFO groundtruth shape(8, 128, 128, 2)\n",
      "2021-07-06 16:36:35,937 INFO original cmr shape(8, 128, 128)\n",
      "2021-07-06 16:36:36,086 INFO (8, 128, 128, 2)\n",
      "2021-07-06 16:36:36,087 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:36,087 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:36,087 INFO (8, 128, 128)\n",
      "2021-07-06 16:36:36,089 INFO patient093\n",
      "2021-07-06 16:36:36,090 INFO 20\n",
      "2021-07-06 16:36:36,090 INFO length of ed_f 10\n",
      "2021-07-06 16:36:36,090 INFO length of es_f 10\n",
      "2021-07-06 16:36:36,091 INFO patient: patient093, phase: ED, files: 10\n",
      "2021-07-06 16:36:36,091 INFO Create DataGenerator\n",
      "2021-07-06 16:36:36,091 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:36,092 INFO No augmentation\n",
      "2021-07-06 16:36:36,125 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:36,157 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:36,311 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:36,312 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:36,313 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:36,313 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:36,315 INFO patient: patient093, phase: ES, files: 10\n",
      "2021-07-06 16:36:36,315 INFO Create DataGenerator\n",
      "2021-07-06 16:36:36,316 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 10 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:36,316 INFO No augmentation\n",
      "2021-07-06 16:36:36,347 INFO groundtruth shape(10, 128, 128, 2)\n",
      "2021-07-06 16:36:36,379 INFO original cmr shape(10, 128, 128)\n",
      "2021-07-06 16:36:36,521 INFO (10, 128, 128, 2)\n",
      "2021-07-06 16:36:36,523 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:36,523 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:36,524 INFO (10, 128, 128)\n",
      "2021-07-06 16:36:36,525 INFO patient095\n",
      "2021-07-06 16:36:36,526 INFO 28\n",
      "2021-07-06 16:36:36,526 INFO length of ed_f 14\n",
      "2021-07-06 16:36:36,526 INFO length of es_f 14\n",
      "2021-07-06 16:36:36,527 INFO patient: patient095, phase: ED, files: 14\n",
      "2021-07-06 16:36:36,527 INFO Create DataGenerator\n",
      "2021-07-06 16:36:36,527 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 14 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:36,528 INFO No augmentation\n",
      "2021-07-06 16:36:36,571 INFO groundtruth shape(14, 128, 128, 2)\n",
      "2021-07-06 16:36:36,614 INFO original cmr shape(14, 128, 128)\n",
      "2021-07-06 16:36:36,779 INFO (14, 128, 128, 2)\n",
      "2021-07-06 16:36:36,780 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:36,781 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:36,781 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:36,783 INFO patient: patient095, phase: ES, files: 14\n",
      "2021-07-06 16:36:36,784 INFO Create DataGenerator\n",
      "2021-07-06 16:36:36,784 INFO Datagenerator created with: \n",
      " shape: [128, 128]\n",
      " spacing: [1.8, 1.8]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 14 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-07-06 16:36:36,785 INFO No augmentation\n",
      "2021-07-06 16:36:36,829 INFO groundtruth shape(14, 128, 128, 2)\n",
      "2021-07-06 16:36:36,873 INFO original cmr shape(14, 128, 128)\n",
      "2021-07-06 16:36:37,034 INFO (14, 128, 128, 2)\n",
      "2021-07-06 16:36:37,036 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:37,036 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:37,036 INFO (14, 128, 128)\n",
      "2021-07-06 16:36:37,039 INFO done! Check the /mnt/ssd/git/wft21_septum_landmark_detection/data/temp_predictions/k-fold_fold3folder for files\n"
     ]
    }
   ],
   "source": [
    "# in short: create one generator per patient\n",
    "# this is a fast hack, it is not very fast\n",
    "# DataGenerator for SAX, changed from PhaseRegression Generator\n",
    "# logging.getLogger().setLevel(logging.INFO)\n",
    "from src.data.Generators import DataGenerator\n",
    "from logging import info\n",
    "config['SHUFFLE'] = False\n",
    "config['AUGMENT'] = False\n",
    "config['AUGMENT_GRID'] = False# make sure no augmentation will be applied to the validation data\n",
    "config['HIST_MATCHING'] = False\n",
    "config['BATCHSIZE'] = 1\n",
    "# by this we can have a different set of parameters for both generators\n",
    "val_config = config.copy()\n",
    "export_root = '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp_predictions/k-fold_fold3'\n",
    "ensure_dir(export_root)\n",
    "\n",
    "df_fold = df[df['modality']=='test']\n",
    "#print(df_fold)\n",
    "\n",
    "# filter a list of filenames by a patient id, this is necessary as the filepath in our df differs from the real filenames\n",
    "def filter_by_patient_id(p_id, f_names):\n",
    "    return [elem for elem in f_names if p_id in elem]\n",
    "\n",
    "\n",
    "#for p in df['patient'].unique(): # show only data on 'unique' patients to sum up folds and slices\n",
    "for p in sorted(df_fold['patient'].unique()): # for each patient\n",
    "    info(p) # shows which patient we are at\n",
    "    files_ = filter_by_patient_id(p, x_val_sax)\n",
    "    masks_ = filter_by_patient_id(p, y_val_sax)\n",
    "    info(len(files_)) # shows amount of slices for each patient\n",
    "    #print(files_[0]) # files is a list with the name of all patient data\n",
    "    # collect all files for this patient\n",
    "    # split in ED and ES\n",
    "    ed_f = files_[:len(files_)//2]\n",
    "    es_f = files_[len(files_)//2:]\n",
    "    ed_m = masks_[:len(masks_)//2]\n",
    "    es_m = masks_[len(masks_)//2:]\n",
    "    f_ = [ed_f, es_f]\n",
    "    m_ = [ed_m, es_m]\n",
    "    phases = ['ED', 'ES']\n",
    "    assert(len(ed_m)==len(ed_f)), 'number of images and masks should be the same, something went wrong'\n",
    "    info('length of ed_f ' + str(len(ed_f)))\n",
    "    info('length of es_f ' + str(len(es_f)))\n",
    "    #print('this is ed_f ' + ed_f)\n",
    "    #print('this is es_f ' + es_f)\n",
    "    for p_ in range(2):\n",
    "        phase_cmr_files = f_[p_] \n",
    "        phase_mask_files = m_[p_]\n",
    "        current_phase = phases[p_]\n",
    "        info('patient: {}, phase: {}, files: {}'.format(p, current_phase, len(phase_cmr_files)))\n",
    "        \n",
    "        validation_generator = DataGenerator(phase_cmr_files, phase_mask_files, config=val_config)\n",
    "\n",
    "        # get cmr mask\n",
    "        gts = np.stack([np.squeeze(y) for x, y in validation_generator])\n",
    "        logging.info('groundtruth shape' + str(gts.shape))\n",
    "        #get cmr image\n",
    "        gts_cmr = np.stack([np.squeeze(x) for x, y in validation_generator])\n",
    "        logging.info('original cmr shape' + str(gts_cmr.shape))\n",
    "\n",
    "        # predict on the validation generator\n",
    "        preds = model.predict(validation_generator)\n",
    "        logging.info(preds.shape)\n",
    "\n",
    "        # upper = 1, lower == 2\n",
    "        # transform to int representation (one-hot)\n",
    "        gts_flat = np.zeros((gts.shape[:-1]))\n",
    "        gts_flat[gts[...,0]>0.5] = 1\n",
    "        gts_flat[gts[...,1]>0.5] = 2\n",
    "\n",
    "        preds_flat = np.zeros((gts.shape[:-1]))\n",
    "        preds_flat[preds[...,0]>0.5] = 1\n",
    "        preds_flat[preds[...,1]>0.5] = 2\n",
    "        \n",
    "        info(gts_flat.shape)\n",
    "        info(preds_flat.shape)\n",
    "        info(gts_cmr.shape)\n",
    "        #print(preds_flat) #NotIncluded\n",
    "        gt_sitks = sitk.GetImageFromArray(gts_flat.astype(np.uint8))\n",
    "        pred_sitks = sitk.GetImageFromArray(preds_flat.astype(np.uint8))\n",
    "        gt_cmr_sitks = sitk.GetImageFromArray(np.stack(gts_cmr, axis = 0))\n",
    "        \n",
    "        #sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_cmr[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_cmr.nrrd')\n",
    "        \n",
    "        # please write here the pred_sitk and gt_sitk and gt_cmr_sitk to disk\n",
    "        sitk.WriteImage(gt_sitks, os.path.join(export_root, '{}_{}_gt.nrrd'.format(p, current_phase)))\n",
    "        sitk.WriteImage(pred_sitks, os.path.join(export_root, '{}_{}_pred.nrrd'.format(p, current_phase)))\n",
    "        sitk.WriteImage(gt_cmr_sitks, os.path.join(export_root, '{}_{}_cmr.nrrd'.format(p, current_phase)))\n",
    "        #sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_cmr[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_new_temp_cmr.nrrd')\n",
    "\n",
    "logging.info('done! Check the ' + export_root + 'folder for files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-05 18:35:43,157 INFO patient098\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code to figure out where we are currently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patient001__t01_z0_img.nrrd'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.path.basename(x_val_sax[0]) #gives basename of the first file from x_val_sax\n",
    "#os.path.split(x_val_sax[0])  # gives directory in which the x_val_sax files are located"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "this gives us info on where the x_val_sax files are stored and what each file is named. But this is not necessarily the way these files sorted by the validation_generator I think? This would mean we need to find out the structure of that one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks_out\n",
    "export_path = '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/'\n",
    "ensure_dir(export_path)\n",
    "_ = [sitk.WriteImage(img, '{}_{}'.format(export_path, os.path.basename(f_name))) for img, f_name in zip(gt_sitks, x_val_sax)]\n",
    "# this might be important, need to figure out what it does exactly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations and Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7daaf2d88934ae28002180e11bc66a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=237, description='elem', max=475), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checks_out\n",
    "#visualizes predictions\n",
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "@interact\n",
    "def show_predictions(elem = (0,len(preds_flat)-1)):\n",
    "    elem = gts_flat[elem]\n",
    "    print(elem.shape)\n",
    "    show_2D_or_3D(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7eac0cfa4db41b582d4a9b616174950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=238, description='elem', max=476), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checks_out\n",
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "@interact\n",
    "def show_predictions(elem = (0, len(x_val_sax))):\n",
    "    temp = x_val_sax[elem]\n",
    "    cmr = sitk.ReadImage(temp)\n",
    "    cmr = sitk.GetArrayFromImage(cmr)\n",
    "    temp = temp.replace('img', 'msk')\n",
    "    temp = sitk.ReadImage(temp)\n",
    "    temp = sitk.GetArrayFromImage(temp)\n",
    "    #plt.imshow(temp, cmap='gray')\n",
    "    \n",
    "    show_2D_or_3D(cmr, temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e6ae19ec314494b7a0c21d74641db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=238, description='elem', max=476), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checks_out\n",
    "\n",
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "@interact\n",
    "def show_predictions(elem = (0,gts.shape[0])):\n",
    "    temp = gts_cmr[elem]\n",
    "    msk = gts_flat[elem]\n",
    "    print(msk.shape)\n",
    "    #plt.imshow(temp, cmap='gray')\n",
    "    #plt.imshow(msk, alpha=0.8)\n",
    "    show_2D_or_3D(temp, msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9080fe31684fd6921d6dd9cadc0377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=237, description='batch', max=475), IntSlider(value=0, description='im',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checks_out\n",
    "\n",
    "generator = validation_generator\n",
    "@interact\n",
    "def select_image_in_batch(batch = (0,len(generator)-1, 1), im = (0,config['BATCHSIZE']- 1, 1), slice_n=(1,11), save=False, filepath='data/temp/', filename='temp_x.npy'):\n",
    "    \n",
    "    global x, y\n",
    "    x, y = generator.__getitem__(batch)\n",
    "    info('selected batch : ' + str(batch))\n",
    "    # logging level == debug --> visualise the generator steps\n",
    "    info('X shape: {}, Y shape: {}'.format(x.shape, y.shape))\n",
    "    show_2D_or_3D(x[im], y[im], interpol='bilinear',dpi=100,f_size=(5,5))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(x[im].flatten())\n",
    "    plt.show()\n",
    "    if save:\n",
    "        ensure_dir(filepath)\n",
    "        np.save(os.path.join(filepath, filename), x[im])\n",
    "        logging.info('saved to {}'.format(os.path.join(filepath, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undo the generator steps\n",
    "\n",
    "- If we have masks, undo the cropping/padding, resampling etc. so that our masks have the same size/spacing and name as our input volumes\n",
    "- If we have regression coordinates, make sure that they could be applied on the input volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the gts, predictions testwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Some sample numpy data\n",
    "\n",
    "# data = np.zeros((5,4,3,2))\n",
    "# filename = 'testdata.nrrd'\n",
    "\n",
    "# # Write to a NRRD file\n",
    "# nrrd.write(filename, data)\n",
    "\n",
    "# # Read the data back from file\n",
    "# readdata, header = nrrd.read(filename)\n",
    "# print(readdata.shape)\n",
    "# print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting numpy predictions into nrrd via pynrrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 3d_nrrd file to disk\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_cmr[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_temp_cmr.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 3d_nrrd file to disk\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_cmr[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_temp_cmr.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foo kernel",
   "language": "python",
   "name": "foo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
