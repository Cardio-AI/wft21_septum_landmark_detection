{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c50b7da",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "# ------------------------------------------define GPU id/s to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "# ------------------------------------------jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# ------------------------------------------ import helpers\n",
    "# this should import glob, os, and some other standard libs to keep this cell clean\n",
    "# local imports\n",
    "from src.utils.Notebook_imports import *\n",
    "from src.utils.Utils_io import Console_and_file_logger, init_config\n",
    "\n",
    "# import external libs\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipyfilechooser import FileChooser\n",
    "import nrrd as nrrd # https://pypi.org/project/pynrrd/\n",
    "from src.data.Generators import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157e5e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b957d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "773390b2",
   "metadata": {},
   "source": [
    "## Hella Sus Code that belongs to different notebooks I Think? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f229efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "\n",
    "results = model.fit(\n",
    "    x=batch_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks = get_callbacks(config, batch_generator,validation_generator),\n",
    "    initial_epoch=initial_epoch,\n",
    "    max_queue_size=12,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the model summary to a txt file\n",
    "# Open the file\n",
    "with open(os.path.join(EXP_PATH, 'model_summary.txt') ,'w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "    \n",
    "tf.keras.utils.plot_model(\n",
    "    model, show_shapes=True,\n",
    "    to_file=os.path.join(EXP_PATH, 'model.png'),\n",
    "    show_layer_names=True, \n",
    "    rankdir='TB', \n",
    "    expand_nested=True, dpi=96\n",
    ")\n",
    "    \n",
    "#model.summary(line_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if all batches are processable\n",
    "\"\"\"for b in range(len(batch_generator)):\n",
    "    print(b)\n",
    "    for im in range(BATCHSIZE):\n",
    "        select_image_in_batch(batch=b,im=im, slice_n=5, show_overview=True, show_input_vol=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d76d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load past config for model training \n",
    "\"\"\"\n",
    "if 'streategy' in locals():\n",
    "    pass\n",
    "else:\n",
    "    # distribute the training with the mirrored data paradigm across multiple gpus if available, if not use gpu 0\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=config.get('GPUS', [\"/gpu:0\"]))\n",
    "\n",
    "import src.models.Unets as modelmanager\n",
    "with strategy.scope():\n",
    "    # create new model\n",
    "    logging.info('Create model')\n",
    "    model = modelmanager.create_unet(config, metrics, supervision=False)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8320b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previous config and by this a pre-trained model\n",
    "from ipyfilechooser import FileChooser\n",
    "config_chooser = FileChooser(os.path.join(os.getcwd(),'reports/configs'), 'config.json')\n",
    "display(config_chooser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc83b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc25721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a875f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01de36b5",
   "metadata": {},
   "source": [
    "## Config Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52104fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config_chooser = FileChooser(os.path.join(os.getcwd(),'exp/cv_baseline'), '')\n",
    "display(exp_config_chooser)\n",
    "@interact_manual\n",
    "def load_config():\n",
    "\n",
    "    global exp_config_chooser, config\n",
    "    \"\"\"\n",
    "    load an experiment config\n",
    "    \"\"\"\n",
    "    if 'exp_config_chooser' in globals():\n",
    "        config_file  = exp_config_chooser.selected\n",
    "    else:\n",
    "        print('no config chooser found')\n",
    "\n",
    "    # load the experiment config\n",
    "    with open(config_file, encoding='utf-8') as data_file:\n",
    "        config = json.loads(data_file.read())\n",
    "    globals().update(config)\n",
    "    Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "    logging.info('Loaded config for experiment: {}'.format(config['EXPERIMENT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3ccd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3797bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf996bfa",
   "metadata": {},
   "source": [
    "## Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabc964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f603fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29253415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95557223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb15714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAX volumes\n",
    "from src.data.Dataset import get_trainings_files\n",
    "x_train_sax, y_train_sax, x_val_sax, y_val_sax = get_trainings_files(data_path=DATA_PATH_SAX,\n",
    "                                                                     path_to_folds_df=DF_FOLDS,\n",
    "                                                                     fold=FOLD)\n",
    "logging.info('SAX train CMR: {}, SAX train masks: {}'.format(len(x_train_sax), len(y_train_sax)))\n",
    "logging.info('SAX val CMR: {}, SAX val masks: {}'.format(len(x_val_sax), len(y_val_sax)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82615257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataGenerator for SAX, changed from PhaseRegression Generator\n",
    "# logging.getLogger().setLevel(logging.INFO)\n",
    "from src.data.Generators import DataGenerator\n",
    "config['SHUFFLE'] = False\n",
    "config['AUGMENT'] = False\n",
    "config['AUGMENT_GRID'] = False# make sure no augmentation will be applied to the validation data\n",
    "config['HIST_MATCHING'] = False\n",
    "config['BATCHSIZE'] = 1\n",
    "batch_generator = DataGenerator(x_train_sax, y_train_sax, config=config)\n",
    "# create another config for the validation data, \n",
    "# by this we can have a different set of parameters for both generators\n",
    "val_config = config.copy()\n",
    "validation_generator = DataGenerator(x_val_sax, y_val_sax, config=val_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ba62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c5a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584474dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93830c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = validation_generator\n",
    "@interact\n",
    "def select_image_in_batch(batch = (0,len(generator)-1, 1), im = (0,config['BATCHSIZE']- 1, 1), slice_n=(1,11), save=False, filepath='data/temp/', filename='temp_x.npy'):\n",
    "    \n",
    "    global x, y\n",
    "    x, y = generator.__getitem__(batch)\n",
    "    info('selected batch : ' + str(batch))\n",
    "    # logging level == debug --> visualise the generator steps\n",
    "    info('X shape: {}, Y shape: {}'.format(x.shape, y.shape))\n",
    "    show_2D_or_3D(x[im], y[im], interpol='bilinear',dpi=100,f_size=(5,5))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(x[im].flatten())\n",
    "    plt.show()\n",
    "    if save:\n",
    "        ensure_dir(filepath)\n",
    "        np.save(os.path.join(filepath, filename), x[im])\n",
    "        logging.info('saved to {}'.format(os.path.join(filepath, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc25512",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = validation_generator\n",
    "@interact\n",
    "def select_image_in_batch(batch = (0,len(generator)-1, 1), im = (0,config['BATCHSIZE']- 1, 1), slice_n=(1,11), save=False, filepath='data/temp/', filename='temp_x.npy'):\n",
    "    \n",
    "    global x, y\n",
    "    x, y = generator.__getitem__(batch)\n",
    "    info('selected batch : ' + str(batch))\n",
    "    # logging level == debug --> visualise the generator steps\n",
    "    info('X shape: {}, Y shape: {}'.format(x.shape, y.shape))\n",
    "    show_2D_or_3D(x[im], y[im], interpol='bilinear',dpi=100,f_size=(5,5))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(x[im].flatten())\n",
    "    plt.show()\n",
    "    if save:\n",
    "        ensure_dir(filepath)\n",
    "        np.save(os.path.join(filepath, filename), x[im])\n",
    "        logging.info('saved to {}'.format(os.path.join(filepath, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c107605",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = validation_generator\n",
    "@interact\n",
    "def select_image_in_batch(batch = (0,len(generator)-1, 1), im = (0,config['BATCHSIZE']- 1, 1), slice_n=(1,11), save=False, filepath='data/temp/', filename='temp_x.npy'):\n",
    "    \n",
    "    global x, y\n",
    "    x, y = generator.__getitem__(batch)\n",
    "    info('selected batch : ' + str(batch))\n",
    "    # logging level == debug --> visualise the generator steps\n",
    "    info('X shape: {}, Y shape: {}'.format(x.shape, y.shape))\n",
    "    show_2D_or_3D(x[im], y[im], interpol='bilinear',dpi=100,f_size=(5,5))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(x[im].flatten())\n",
    "    plt.show()\n",
    "    if save:\n",
    "        ensure_dir(filepath)\n",
    "        np.save(os.path.join(filepath, filename), x[im])\n",
    "        logging.info('saved to {}'.format(os.path.join(filepath, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d645ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAX volumes\n",
    "x_train, y_train, x_val, y_val =  get_trainings_files(data_path=DATA_PATH_SAX,path_to_folds_df=DF_FOLDS, fold=FOLD)\n",
    "logging.info('SAX train CMR: {}, SAX train masks: {}'.format(len(x_train), len(y_train)))\n",
    "logging.info('SAX val CMR: {}, SAX val masks: {}'.format(len(x_val), len(y_val)))\n",
    "\n",
    "# create a batch generator\n",
    "batch_generator = DataGenerator(x_train, y_train, config=config)\n",
    "val_config = config.copy()\n",
    "val_config['AUGMENT_GRID'] = False# make sure no augmentation will be applied to the validation data\n",
    "val_config['AUGMENT'] = False\n",
    "val_config['HIST_MATCHING'] = False\n",
    "validation_generator = DataGenerator(x_val, y_val , config=val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f2940",
   "metadata": {},
   "source": [
    "### sus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cceed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = validation_generator\n",
    "@interact\n",
    "def select_image_in_batch(batch = (0,len(generator), 1), im = (0,BATCHSIZE- 1, 1), slice_n=(1,11), save=False, filepath='data/temp/', filename='temp_x.npy'):\n",
    "    \n",
    "    global x, y\n",
    "    x, y = generator.__getitem__(batch)\n",
    "    info('selected batch : ' + str(batch))\n",
    "    # logging level == debug --> visualise the generator steps\n",
    "    info('X shape: {}, Y shape: {}'.format(x.shape, y.shape))\n",
    "    show_2D_or_3D(x[im], y[im], interpol='bilinear',dpi=100,f_size=(5,5))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(x[im].flatten())\n",
    "    plt.show()\n",
    "    if save:\n",
    "        ensure_dir(filepath)\n",
    "        np.save(os.path.join(filepath, filename), x[im])\n",
    "        logging.info('saved to {}'.format(os.path.join(filepath, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAX volumes\n",
    "x_train, y_train, x_val, y_val =  get_trainings_files(data_path=DATA_PATH_SAX,path_to_folds_df=DF_FOLDS, fold=FOLD)\n",
    "logging.info('SAX train CMR: {}, SAX train masks: {}'.format(len(x_train), len(y_train)))\n",
    "logging.info('SAX val CMR: {}, SAX val masks: {}'.format(len(x_val), len(y_val)))\n",
    "\n",
    "# create a batch generator\n",
    "batch_generator = DataGenerator(x_train, y_train, config=config)\n",
    "val_config = config.copy()\n",
    "val_config['AUGMENT_GRID'] = False# make sure no augmentation will be applied to the validation data\n",
    "val_config['AUGMENT'] = False\n",
    "val_config['HIST_MATCHING'] = False\n",
    "validation_generator = DataGenerator(x_val, y_val , config=val_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfb6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e637465f",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90e6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network for SAX as Unet, changed from PhaseRegressionModel\n",
    "import src.models.Unets as modelmanager\n",
    "# create a model\n",
    "logging.info('Create model')\n",
    "model = modelmanager.create_unet(config)\n",
    "model.load_weights(os.path.join(config['MODEL_PATH'],'model.h5'))\n",
    "logging.info('loaded model weights as h5 file')\n",
    "model.summary()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c915c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4716dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826e1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148528b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5fccdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec50945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b09ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b9b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94c60b43",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe903a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "gts = stack[0]\n",
    "preds = stack[1]\n",
    "\n",
    "# upper = 1, lower == 2\n",
    "# transform to int representation (one-hot)\n",
    "gts_flat = np.zeros((gts.shape[:-1]))\n",
    "gts_flat[gts[...,0]>0.5] = 1\n",
    "gts_flat[gts[...,1]>0.5] = 2\n",
    "\n",
    "preds_flat = np.zeros((gts.shape[:-1]))\n",
    "preds_flat[preds[...,0]>0.5] = 1\n",
    "preds_flat[preds[...,1]>0.5] = 2\n",
    "print(preds_flat.shape)\n",
    "gt_sitks = [sitk.GetImageFromArray(elem) for elem in gts_flat]\n",
    "pred_sitks = [sitk.GetImageFromArray(elem) for elem in preds_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "gts = stack[0]\n",
    "preds = stack[1]\n",
    "\n",
    "# upper = 1, lower == 2\n",
    "# transform to int representation (one-hot)\n",
    "gts_flat = np.zeros((gts.shape[:-1]))\n",
    "gts_flat[gts[...,0]>0.5] = 1\n",
    "gts_flat[gts[...,1]>0.5] = 2\n",
    "\n",
    "preds_flat = np.zeros((gts.shape[:-1]))\n",
    "preds_flat[preds[...,0]>0.5] = 1\n",
    "preds_flat[preds[...,1]>0.5] = 2\n",
    "print(preds_flat.shape)\n",
    "print(preds_flat)\n",
    "gt_sitks = [sitk.GetImageFromArray(elem) for elem in gts_flat]\n",
    "pred_sitks = [sitk.GetImageFromArray(elem) for elem in preds_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80078170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "gts = stack[0]\n",
    "preds = stack[1]\n",
    "\n",
    "# upper = 1, lower == 2\n",
    "# transform to int representation (one-hot)\n",
    "gts_flat = np.zeros((gts.shape[:-1]))\n",
    "gts_flat[gts[...,0]>0.5] = 1\n",
    "gts_flat[gts[...,1]>0.5] = 2\n",
    "\n",
    "preds_flat = np.zeros((gts.shape[:-1]))\n",
    "preds_flat[preds[...,0]>0.5] = 1\n",
    "preds_flat[preds[...,1]>0.5] = 2\n",
    "print(preds_flat.shape)\n",
    "gt_sitks = [sitk.GetImageFromArray(elem) for elem in gts_flat]\n",
    "pred_sitks = [sitk.GetImageFromArray(elem) for elem in preds_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a194e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "gts = stack[0]\n",
    "preds = stack[1]\n",
    "\n",
    "# upper = 1, lower == 2\n",
    "# transform to int representation (one-hot)\n",
    "gts_flat = np.zeros((gts.shape[:-1]))\n",
    "gts_flat[gts[...,0]>0.5] = 1\n",
    "gts_flat[gts[...,1]>0.5] = 2\n",
    "\n",
    "preds_flat = np.zeros((gts.shape[:-1]))\n",
    "preds_flat[preds[...,0]>0.5] = 1\n",
    "preds_flat[preds[...,1]>0.5] = 2\n",
    "print(preds_flat.shape)\n",
    "gt_sitks = [sitk.GetImageFromArray(elem) for elem in gts_flat]\n",
    "pred_sitks = [sitk.GetImageFromArray(elem) for elem in preds_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bcee15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2905d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228feb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc228889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation generator\n",
    "preds = model.predict(validation_generator)\n",
    "logging.info(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8501d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gts_cmr = np.stack([np.squeeze(x) for x, y in validation_generator])\n",
    "logging.info(gts_cmr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all ground truth vectors\n",
    "gts = np.stack([np.squeeze(y) for x, y in validation_generator])\n",
    "logging.info(gts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180f35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecc289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428e441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e45bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['fold']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate of code that is further on top\n",
    "for p in sorted(df['patient'].unique()):\n",
    "    print(p) #prints patient\n",
    "    files_ = df[df['patient'] ==p]['x_path'].values\n",
    "    print(len(files_))\n",
    "    ed_f = files_[:len(files_)//2] # first half of slices are ed\n",
    "    es_f = files_[len(files_)//2:] # second half of slices are es\n",
    "    print(len(ed_f)) #prints amount of slices for ED.\n",
    "    print(len(es_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90987cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(DF_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5bf501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b810511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85825c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate of code that is further on top\n",
    "for p in sorted(df['patient'].unique()):\n",
    "    print(p) #prints patient\n",
    "    files_ = df[df['patient'] ==p]['x_path'].values\n",
    "    print(len(files_))\n",
    "    ed_f = files_[:len(files_)//2] # first half of slices are ed\n",
    "    es_f = files_[len(files_)//2:] # second half of slices are es\n",
    "    print(len(ed_f)) #prints amount of slices for ED.\n",
    "    print(len(es_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e8926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c574b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6abdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the validation generator\n",
    "preds = model.predict(batch_generator)\n",
    "logging.info(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34206629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014e764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 3d_nrrd file to disk\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_cmr[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_temp_cmr.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce23185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 3d_nrrd file to disk\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.stack(gts_flat[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_temp_gt.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write 3d_nrrd file to disk\n",
    "sitk.WriteImage(sitk.GetImageFromArray(np.stack(preds_flat[:10], axis=0)), '/mnt/ssd/git/wft21_septum_landmark_detection/data/temp/3d_temp.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a9ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869a750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e889b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792baf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ffa98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe13998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb9dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8349e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.load('/mnt/ssd/git/wft21_septum_landmark_detection/{}'.format(pred_filename))\n",
    "\n",
    "stack = np.load('/mnt/ssd/git/wft21_septum_landmark_detection/{}'.format(pred_filename))\n",
    "print('the shape of the numpy.stack is' + str(np.shape(stack)))\n",
    "print(('loading from: /mnt/ssd/git/wft21_septum_landmark_detection/{}'.format(pred_filename)))\n",
    "\n",
    "#for-loop over stack --> reading numpy and transferring with pynrrd. pad_and_crop function applied. saving with the name of original file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = os.path.join(config['EXP_PATH'], 'pred_'+ str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "ensure_dir(pred_path)\n",
    "pred_filename = os.path.join(pred_path, 'gtpred_fold{}.npy'.format(config['FOLD'])) #names file according to fold\n",
    "np.save(pred_filename, np.stack([gts, preds], axis=0))\n",
    "logging.info('saved as: \\n{} \\ndone!'.format(pred_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5937554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = os.path.join(config['EXP_PATH'], 'pred_'+ str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M\")))\n",
    "ensure_dir(pred_path)\n",
    "pred_filename = os.path.join(pred_path, 'gtpred_fold{}.npy'.format(config['FOLD'])) #names file according to fold\n",
    "np.save(pred_filename, np.stack([gts, preds], axis=0))\n",
    "logging.info('saved as: \\n{} \\ndone!'.format(pred_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5f581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90197c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b92ee0c",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180951c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "@interact\n",
    "def show_predictions(elem = (0,len(gts_flat)-1)):\n",
    "    elem = gts_flat[elem]\n",
    "    print(elem.shape)\n",
    "    show_2D_or_3D(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f97764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "@interact\n",
    "def show_predictions(elem = (0,gts.shape[0])):\n",
    "    temp = gts_cmr[elem]\n",
    "    msk = gts_flat[elem]\n",
    "    print(msk.shape)\n",
    "    #plt.imshow(temp, cmap='gray')\n",
    "    plt.imshow(msk, alpha=0.8)\n",
    "    #show_2D_or_3D(temp, msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381bf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "@interact\n",
    "def show_predictions(elem = (0,len(preds_flat)-1)):\n",
    "    elem = gts_flat[elem]\n",
    "    print(elem.shape)\n",
    "    show_2D_or_3D(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afe360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "@interact\n",
    "def show_predictions(elem = (0,gts.shape[0])):\n",
    "    temp = gts_cmr[elem]\n",
    "    msk = preds_flat[elem]\n",
    "    print(msk.shape)\n",
    "    #plt.imshow(temp, cmap='gray')\n",
    "    #plt.imshow(msk, alpha=0.8)\n",
    "    show_2D_or_3D(temp, msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29627e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualization.Visualize import show_2D_or_3D\n",
    "@interact\n",
    "def show_predictions(elem = (0,gts.shape[0])):\n",
    "    temp = gts_cmr[elem]\n",
    "    msk = gts_flat[elem]\n",
    "    print(msk.shape)\n",
    "    #plt.imshow(temp, cmap='gray')\n",
    "    #plt.imshow(msk, alpha=0.8)\n",
    "    show_2D_or_3D(temp, msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6369c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269c761f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219010d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foo kernel",
   "language": "python",
   "name": "foo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
